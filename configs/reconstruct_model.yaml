# constants
SEED: 101
WANDB_API_KEY: bdc8857f9d6f7010cff35bcdc0ae9413e05c75e1

# modules state
project_name: federated-pet
dir_name: runs/patch-reconstruction-model-64x64
name: Reconstruction model 64x64 (VariationalAutoencoder)

datamodule:
    root: ../datasets/EARL/Ano_Nifti/
    pattern: PT_TEPTAPAC_Ano_MIP
    train_ratio: 0.95
    batch_size: 32
    num_workers: 32
    shuffle: true
    verbose: true
    random_crop_size: [64, 64]
    horizontal_flip: 0.5
    vertical_flip: 0.5

model:
    in_channels: 1
    out_channels: 1
    spatial_dims: 3
    emb_channels: 8
    hid_chs: [64, 128, 256, 512]
    kernel_sizes: [3, 3, 3, 3]
    strides: [1, 2, 2, 2]
    norm_name: [instance, {affine: true}]
    act_name: [swish, {}]
    temb_channels: null
    max_period: 1000
    dropout: null
    use_res_block: true
    deep_supervision: false
    learnable_interpolation: true
    use_attention: none
    embedding_loss_weight: 5e-7
    perceiver_kwargs: {}
    perceptual_loss_weight: 1.0
    optimizer_kwargs: {lr: 1e-5}
    lr_scheduler: null
    lr_scheduler_kwargs: {}
    use_ssim_loss: true
    use_perceptual_loss: false
    sample_every_n_steps: 50

# trainer state
model_checkpoint:
    monitor: val/loss_epoch
    every_n_epochs: 100
    save_last: true
    save_top_k: 1
    mode: min

trainer:
    precision: 32
    accelerator: gpu
    enable_checkpointing: true
    log_every_n_steps: 1
    min_epochs: 100
    max_epochs: 30000
    check_val_every_n_epoch: 1
